---
title: "randomForest"
author: "laurie dussere"
date: "23/03/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(ggplot2)
library(corrplot)
library("xlsx")
library(FactoMineR)
library(factoextra)
library(cowplot)
library("NbClust")
library(readxl)
library(missForest)
library(glmnet)
library(MASS)
library(leaps)
library(bestglm)
library(logistf)


library(rpart)
library(dplyr)
library(randomForest)
```

```{r}
data= read_excel("tableau_complet_Gscore.xlsx")

data=transform(data,GPD =as.numeric(GPD),Gender_Gap =as.numeric(Gender_Gap),Ethnic =as.numeric(Ethnic),Linguistic =as.numeric(Linguistic),Religious =as.numeric(Religious),Science_and_Technology =as.numeric(Science_and_Technology),Culture=as.numeric(Culture),International_Peace_and_Security=as.numeric(International_Peace_and_Security),World_Order=as.numeric(World_Order),Planet_and_Climate=as.numeric(Planet_and_Climate),Prosperity_and_Equality=as.numeric(Prosperity_and_Equality),Health_and_Well_being=as.numeric(Health_and_Well_being),Emigrants=as.numeric(Emigrants),Suicide_Both_sexes=as.numeric(Suicide_Both_sexes),Suicide_Men=as.numeric(Suicide_Men),Suicide_Women=as.numeric(Suicide_Women),National_power=as.numeric(National_power),Population=as.numeric(Population),HDI=as.numeric(HDI),Corruption=as.numeric(Corruption),Terrorism=as.numeric(Terrorism),Poverty_pct=as.numeric(Poverty_pct),Gscore=as.numeric(Gscore))

rownames(data)<-data$Countries
data=data[,-1]
data=data[,-14]

data =data %>% filter(!is.na(Gscore))

head(data)
```

Le nombre d’arbres que la modèle va utiliser – ntree

Le nombre de variables testées à chaque division d’un noeud – mtry 

dans la classification : on prend en général mtry=racine(du nombre de variable)
dans la régression : mtry=nb_variables/3


## Cas de la régression 
```{r}
# Algorithme Random Forest  
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 100, 
                                  mtry = 7, na.action = na.roughfix)

print(Gscore_RandomForest)

```

Comme pour tout modèle construit par agrégation ou boîte noire, il n’y a
pas d’interprétation directe. Néanmoins des informations pertinentes sont obtenues par le calcul et la représentation graphique d’indices proportionnels à
l’importance de chaque variable dans le modèle agrégé et donc de sa participation à la régression ou à la discrimination. C’est évidemment d’autant plus
utile que les variables sont très nombreuses. Deux critères sont ainsi proposés
pour évaluer l’importance de la jème variable.


```{r}
#Variables d'importance 
Gscore_RandomForest$importance[order(Gscore_RandomForest$importance[, 1], 
                            decreasing = TRUE), ]
```
Les variables les plus importantes sont Culture, Corruption, World_Order,Planet and Climate, Gender_Gap, HDI.

## Cas de la classification

```{r}
data= read_excel("tableau_complet_Gscore.xlsx")

data=transform(data,GPD =as.numeric(GPD),Gender_Gap =as.numeric(Gender_Gap),Ethnic =as.numeric(Ethnic),Linguistic =as.numeric(Linguistic),Religious =as.numeric(Religious),Science_and_Technology =as.numeric(Science_and_Technology),Culture=as.numeric(Culture),International_Peace_and_Security=as.numeric(International_Peace_and_Security),World_Order=as.numeric(World_Order),Planet_and_Climate=as.numeric(Planet_and_Climate),Prosperity_and_Equality=as.numeric(Prosperity_and_Equality),Health_and_Well_being=as.numeric(Health_and_Well_being),Emigrants=as.numeric(Emigrants),Suicide_Both_sexes=as.numeric(Suicide_Both_sexes),Suicide_Men=as.numeric(Suicide_Men),Suicide_Women=as.numeric(Suicide_Women),National_power=as.numeric(National_power),Population=as.numeric(Population),HDI=as.numeric(HDI),Corruption=as.numeric(Corruption),Terrorism=as.numeric(Terrorism),Poverty_pct=as.numeric(Poverty_pct),Gscore=as.numeric(Gscore))

rownames(data)<-data$Countries
data=data[,-1]
data=data[,-14]

data =data %>% filter(!is.na(Gscore))
```

```{r}
data$Gscore[data$Gscore >= 5] <- 1
data$Gscore[data$Gscore !=1] <- 0
```

```{r}
# Algorithme Random Forest
data[,"Gscore"]=as.factor(data[,"Gscore"])
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 8000, 
                                  mtry = 5, na.action = na.roughfix)

print(Gscore_RandomForest)
```


```{r}
plot(Gscore_RandomForest$err.rate[, 1], type = "l", xlab = "nombre d'arbres", ylab = "erreur OOB")
```

OOB estimate of  error rate: 23.61% : Il s’agit de l’erreur moyenne calculée, à chaque fois, sur les échantillons qui n’ont pas servis à calculer le modèle.


```{r}
# Algorithme Random Forest
data[,"Gscore"]=as.factor(data[,"Gscore"])
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 3000, #il faut choisir le bon ntree
                                  mtry = 5, na.action = na.roughfix)

print(Gscore_RandomForest)
```

Chaque arbre de la forêt est construit sur une fraction ("in bag") des données (c'est la fraction qui sert à l'entraînement de l'algorithme. Alors pour chacun des individus de la fraction restante ("out of bag") l'arbre peut prédire une classe.


Nous avons egalement l'affichage de la matrice de confusion, nous remarquons que qu'il y a 23% d'erreurs pour les 2 catégories (démocratiques et non démocratique)

### Importance des variables : 
```{r}
varImpPlot(Gscore_RandomForest)
```


```{r}
Gscore_RandomForest$importance[order(Gscore_RandomForest$importance[, 1], decreasing = TRUE), ]
```
Dans le modèle calculé, les 3 élements qui comptent le plus pour distinguer démocratie/non démocratie sont la culture, gender_gap et la corruption. On peut examiner graphiquement ces élements

```{r}
plot(Gscore ~ Culture, data = data)
```

On voit que les pays démocratiques sont plus nombreux à avoir une variable culture inférieure à 100.

```{r}
plot(Gscore ~ Corruption, data = data)
```
Les pays non démocratiques ont une variable corruption faible (cad beaucoup de corruption dans le pays)


```{r}
plot(Gscore ~ Gender_Gap, data = data)
```


## Idem mais uniquement sur le sous jeu de données 

```{r}
data= read_excel("tableau_complet_Gscore.xlsx")

data=transform(data,GPD =as.numeric(GPD),Gender_Gap =as.numeric(Gender_Gap),Ethnic =as.numeric(Ethnic),Linguistic =as.numeric(Linguistic),Religious =as.numeric(Religious),Science_and_Technology =as.numeric(Science_and_Technology),Culture=as.numeric(Culture),International_Peace_and_Security=as.numeric(International_Peace_and_Security),World_Order=as.numeric(World_Order),Planet_and_Climate=as.numeric(Planet_and_Climate),Prosperity_and_Equality=as.numeric(Prosperity_and_Equality),Health_and_Well_being=as.numeric(Health_and_Well_being),Emigrants=as.numeric(Emigrants),Suicide_Both_sexes=as.numeric(Suicide_Both_sexes),Suicide_Men=as.numeric(Suicide_Men),Suicide_Women=as.numeric(Suicide_Women),National_power=as.numeric(National_power),Population=as.numeric(Population),HDI=as.numeric(HDI),Corruption=as.numeric(Corruption),Terrorism=as.numeric(Terrorism),Poverty_pct=as.numeric(Poverty_pct),Gscore=as.numeric(Gscore))

rownames(data)<-data$Countries
data=data[,-1]
data=data[,-14]

data =data %>% filter(!is.na(Gscore))

head(data)
```

```{r}
data=subset(data,Gscore>7.5 | Gscore <3.5) #pays les plus démocratiques
```

## Cas de la régression 


```{r}
# Algorithme Random Forest  
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 100, 
                                  mtry = 7, na.action = na.roughfix)

print(Gscore_RandomForest)
```

```{r}
#Variables d'importance 
Gscore_RandomForest$importance[order(Gscore_RandomForest$importance[, 1], 
                            decreasing = TRUE), ]
```
## Cas de la classification

```{r}
data= read_excel("tableau_complet_Gscore.xlsx")

data=transform(data,GPD =as.numeric(GPD),Gender_Gap =as.numeric(Gender_Gap),Ethnic =as.numeric(Ethnic),Linguistic =as.numeric(Linguistic),Religious =as.numeric(Religious),Science_and_Technology =as.numeric(Science_and_Technology),Culture=as.numeric(Culture),International_Peace_and_Security=as.numeric(International_Peace_and_Security),World_Order=as.numeric(World_Order),Planet_and_Climate=as.numeric(Planet_and_Climate),Prosperity_and_Equality=as.numeric(Prosperity_and_Equality),Health_and_Well_being=as.numeric(Health_and_Well_being),Emigrants=as.numeric(Emigrants),Suicide_Both_sexes=as.numeric(Suicide_Both_sexes),Suicide_Men=as.numeric(Suicide_Men),Suicide_Women=as.numeric(Suicide_Women),National_power=as.numeric(National_power),Population=as.numeric(Population),HDI=as.numeric(HDI),Corruption=as.numeric(Corruption),Terrorism=as.numeric(Terrorism),Poverty_pct=as.numeric(Poverty_pct),Gscore=as.numeric(Gscore))

rownames(data)<-data$Countries
data=data[,-1]
data=data[,-14]

data =data %>% filter(!is.na(Gscore))

data=subset(data,Gscore>7.5 | Gscore <3.5) #pays les plus démocratiques
```

```{r}
data$Gscore[data$Gscore >= 5] <- 1
data$Gscore[data$Gscore !=1] <- 0
```

```{r}
# Algorithme Random Forest
data[,"Gscore"]=as.factor(data[,"Gscore"])
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 8000, 
                                  mtry = 5, na.action = na.roughfix)

print(Gscore_RandomForest)
```


```{r}
plot(Gscore_RandomForest$err.rate[, 1], type = "l", xlab = "nombre d'arbres", ylab = "erreur OOB")
```

OOB estimate of  error rate: 23.61% : Il s’agit de l’erreur moyenne calculée, à chaque fois, sur les échantillons qui n’ont pas servis à calculer le modèle.


```{r}
# Algorithme Random Forest
data[,"Gscore"]=as.factor(data[,"Gscore"])
Gscore_RandomForest <- randomForest(Gscore~.,data=data, ntree = 2000, #il faut choisir le bon ntree
                                  mtry = 5, na.action = na.roughfix)

print(Gscore_RandomForest)
```

Chaque arbre de la forêt est construit sur une fraction ("in bag") des données (c'est la fraction qui sert à l'entraînement de l'algorithme. Alors pour chacun des individus de la fraction restante ("out of bag") l'arbre peut prédire une classe.


Nous avons egalement l'affichage de la matrice de confusion, nous remarquons que qu'il y a 23% d'erreurs pour les 2 catégories (démocratiques et non démocratique)

### Importance des variables : 
```{r}
varImpPlot(Gscore_RandomForest)
```


```{r}
Gscore_RandomForest$importance[order(Gscore_RandomForest$importance[, 1], decreasing = TRUE), ]
```
